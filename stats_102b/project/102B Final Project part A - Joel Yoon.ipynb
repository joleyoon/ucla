{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 102B Final Project Part A (Python)\n",
        "Converted from the original R script to a Python notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Soft-thresholding function\n",
        "\n",
        "def soft_threshold(z, lambda_val):\n",
        "    return np.sign(z) * np.maximum(np.abs(z) - lambda_val, 0)\n",
        "\n",
        "\n",
        "# Coordinate Descent for Lasso Regression\n",
        "\n",
        "def cd_lasso(X, y, lambda_val, tol=1e-4, max_iter=200):\n",
        "    n_obs, n_feat = X.shape\n",
        "    beta_vec = np.zeros(n_feat)\n",
        "    for _ in range(max_iter):\n",
        "        beta_prev = beta_vec.copy()\n",
        "        for j in range(n_feat):\n",
        "            r_j = y - X @ beta_vec + X[:, j] * beta_vec[j]\n",
        "            rho_j = np.sum(X[:, j] * r_j) / n_obs\n",
        "            denom_j = np.sum(X[:, j] ** 2) / n_obs\n",
        "            beta_vec[j] = soft_threshold(rho_j, lambda_val) / denom_j\n",
        "        diff_norm = np.sqrt(np.sum((beta_vec - beta_prev) ** 2))\n",
        "        if diff_norm < tol:\n",
        "            break\n",
        "    return beta_vec\n",
        "\n",
        "\n",
        "# Lambda grid generation\n",
        "\n",
        "def make_lambda_grid(X, y, grid_size=10):\n",
        "    X_centered = X - X.mean(axis=0, keepdims=True)\n",
        "    y_centered = y - y.mean()\n",
        "    n = X.shape[0]\n",
        "    lambda_max = np.max(np.abs(X_centered.T @ y_centered)) / n\n",
        "    lambda_seq = np.exp(np.linspace(np.log(lambda_max), np.log(lambda_max * 1e-3), grid_size))\n",
        "    return lambda_seq\n",
        "\n",
        "\n",
        "# Main model training and evaluation function\n",
        "\n",
        "def fit_and_eval(file_train, file_test, grid_size=10):\n",
        "    df = pd.read_csv(file_train)\n",
        "    X_all = df.iloc[:, :600].to_numpy()\n",
        "    y_all = df.iloc[:, 600].to_numpy(dtype=float)\n",
        "\n",
        "    n_total = X_all.shape[0]\n",
        "    split_index = int(np.floor(0.8 * n_total))\n",
        "    X_train = X_all[:split_index]\n",
        "    y_train = y_all[:split_index]\n",
        "    X_vali = X_all[split_index:]\n",
        "    y_vali = y_all[split_index:]\n",
        "\n",
        "    X_mean = X_train.mean(axis=0)\n",
        "    y_mean = y_train.mean()\n",
        "    X_train_c = X_train - X_mean\n",
        "    y_train_c = y_train - y_mean\n",
        "    X_vali_c = X_vali - X_mean\n",
        "\n",
        "    lambda_values = make_lambda_grid(X_train, y_train, grid_size)\n",
        "    val_errors = np.zeros(len(lambda_values))\n",
        "\n",
        "    for i, lam in enumerate(lambda_values):\n",
        "        beta_hat = cd_lasso(X_train_c, y_train_c, lam)\n",
        "        intercept = y_mean - np.sum(beta_hat * X_mean)\n",
        "        y_pred = X_vali @ beta_hat + intercept\n",
        "        val_errors[i] = np.mean((y_vali - y_pred) ** 2)\n",
        "\n",
        "    best_idx = int(np.argmin(val_errors))\n",
        "    best_lambda = lambda_values[best_idx]\n",
        "\n",
        "    X_combined = np.vstack([X_train, X_vali])\n",
        "    y_combined = np.concatenate([y_train, y_vali])\n",
        "    X_comb_mean = X_combined.mean(axis=0)\n",
        "    y_comb_mean = y_combined.mean()\n",
        "    X_comb_c = X_combined - X_comb_mean\n",
        "    y_comb_c = y_combined - y_comb_mean\n",
        "\n",
        "    final_beta = cd_lasso(X_comb_c, y_comb_c, best_lambda)\n",
        "    final_intercept = y_comb_mean - np.sum(final_beta * X_comb_mean)\n",
        "\n",
        "    df_test = pd.read_csv(file_test)\n",
        "    X_test = df_test.iloc[:, :600].to_numpy()\n",
        "    y_test = df_test.iloc[:, 600].to_numpy(dtype=float)\n",
        "    y_test_pred = X_test @ final_beta + final_intercept\n",
        "    test_mse = np.mean((y_test - y_test_pred) ** 2)\n",
        "\n",
        "    return {\n",
        "        \"lambda\": best_lambda,\n",
        "        \"nonzero\": np.where(final_beta != 0)[0] + 1,\n",
        "        \"test_mse\": test_mse,\n",
        "        \"val_errors\": val_errors,\n",
        "        \"lambda_values\": lambda_values,\n",
        "    }\n",
        "\n",
        "\n",
        "# File paths\n",
        "\n",
        "data_dir = Path('.')\n",
        "file_test = data_dir / 'test_data.csv'\n",
        "nodes = [\n",
        "    data_dir / 'regression_data_node1.csv',\n",
        "    data_dir / 'regression_data_node2.csv',\n",
        "    data_dir / 'regression_data_node3.csv',\n",
        "]\n",
        "\n",
        "results_list = []\n",
        "val_plot_rows = []\n",
        "\n",
        "for i, file_train in enumerate(nodes, start=1):\n",
        "    print(f\"\n",
        "RESULT NODE {i}\")\n",
        "\n",
        "    result = fit_and_eval(file_train, file_test, grid_size=10)\n",
        "\n",
        "    print(f\"Best lambda: {result['lambda']}\")\n",
        "    print(\"Indices of the non-zero regression coefficients:\", result[\"nonzero\"])\n",
        "    print(f\"Test loss of the final model selected: {result['test_mse']:.6f}\")\n",
        "\n",
        "    for lam, val_err in zip(result[\"lambda_values\"], result[\"val_errors\"]):\n",
        "        val_plot_rows.append({\n",
        "            \"Node\": f\"Node {i}\",\n",
        "            \"Lambda\": lam,\n",
        "            \"Validation_MSE\": val_err,\n",
        "        })\n",
        "    results_list.append(result)\n",
        "\n",
        "val_plot_data = pd.DataFrame(val_plot_rows)\n",
        "\n",
        "# Plot validation MSE vs log(lambda)\n",
        "plt.figure(figsize=(8, 4))\n",
        "for node, df_node in val_plot_data.groupby(\"Node\"):\n",
        "    plt.plot(np.log(df_node[\"Lambda\"]), df_node[\"Validation_MSE\"], marker='o', label=node)\n",
        "plt.title(\"Validation MSE vs log(Lambda)\")\n",
        "plt.xlabel(\"log(Lambda)\")\n",
        "plt.ylabel(\"Validation MSE\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "common_nzc = set(results_list[0][\"nonzero\"]).intersection(\n",
        "    results_list[1][\"nonzero\"], results_list[2][\"nonzero\"]\n",
        ")\n",
        "print(\"\n",
        "Indices of the regression coefficients that are non-zero across all three models:\")\n",
        "print(\", \".join(str(idx) for idx in sorted(common_nzc)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}