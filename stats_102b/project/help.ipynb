{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Help (Python)\n",
        "Converted from the original RMarkdown to a Python notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Function that implements Coordinate Descent for LASSO Regression\n",
        "\n",
        "def cd_lasso(y, X, beta=None, tol=1e-6, iter=1000, lambda_val=0.1):\n",
        "    p = X.shape[1]\n",
        "    n = X.shape[0]\n",
        "    if beta is None:\n",
        "        beta = np.zeros(p)\n",
        "\n",
        "    def prox(z, lam):\n",
        "        return np.sign(z) * np.maximum(np.abs(z) - lam, 0)\n",
        "\n",
        "    denominator = np.sum(X ** 2, axis=0)\n",
        "    r = y - X @ beta\n",
        "\n",
        "    for _ in range(iter):\n",
        "        beta_old = beta.copy()\n",
        "        for j in range(p):\n",
        "            xj = X[:, j]\n",
        "            rj = r + beta[j] * xj\n",
        "            numerator = xj @ rj\n",
        "            beta[j] = prox(numerator, lambda_val) / denominator[j]\n",
        "            r = rj - beta[j] * xj\n",
        "\n",
        "        if np.sqrt(np.sum((beta - beta_old) ** 2)) < tol:\n",
        "            break\n",
        "\n",
        "    return beta\n",
        "\n",
        "\n",
        "# PART A\n",
        "\n",
        "data_dir = Path('.')\n",
        "\n",
        "# Reading data\n",
        "\n",
        "data1 = pd.read_csv(data_dir / \"regression_data_node1.csv\")\n",
        "data2 = pd.read_csv(data_dir / \"regression_data_node2.csv\")\n",
        "data3 = pd.read_csv(data_dir / \"regression_data_node3.csv\")\n",
        "test_data = pd.read_csv(data_dir / \"test_data.csv\")\n",
        "\n",
        "# Train/Validation splits\n",
        "\n",
        "data1_train = data1.iloc[:160]\n",
        "data1_val = data1.iloc[160:200]\n",
        "\n",
        "data2_train = data2.iloc[:240]\n",
        "data2_val = data2.iloc[240:300]\n",
        "\n",
        "data3_train = data3.iloc[:400]\n",
        "data3_val = data3.iloc[400:500]\n",
        "\n",
        "\n",
        "test_y = test_data[\"y\"].to_numpy(dtype=float)\n",
        "test_x = test_data.drop(columns=[\"y\"]).to_numpy()\n",
        "\n",
        "# Divide by predictor/response\n",
        "\n",
        "d1train_y = data1_train[\"y\"].to_numpy(dtype=float)\n",
        "d1train_x = data1_train.drop(columns=[\"y\"]).to_numpy()\n",
        "d1val_y = data1_val[\"y\"].to_numpy(dtype=float)\n",
        "d1val_x = data1_val.drop(columns=[\"y\"]).to_numpy()\n",
        "\n",
        "d2train_y = data2_train[\"y\"].to_numpy(dtype=float)\n",
        "d2train_x = data2_train.drop(columns=[\"y\"]).to_numpy()\n",
        "d2val_y = data2_val[\"y\"].to_numpy(dtype=float)\n",
        "d2val_x = data2_val.drop(columns=[\"y\"]).to_numpy()\n",
        "\n",
        "d3train_y = data3_train[\"y\"].to_numpy(dtype=float)\n",
        "d3train_x = data3_train.drop(columns=[\"y\"]).to_numpy()\n",
        "d3val_y = data3_val[\"y\"].to_numpy(dtype=float)\n",
        "d3val_x = data3_val.drop(columns=[\"y\"]).to_numpy()\n",
        "\n",
        "\n",
        "all_training = [\n",
        "    [d1train_x, d1train_y, d1val_x, d1val_y],\n",
        "    [d2train_x, d2train_y, d2val_x, d2val_y],\n",
        "    [d3train_x, d3train_y, d3val_x, d3val_y],\n",
        "]\n",
        "\n",
        "potential_lambdas = np.arange(0.05, 1.01, 0.05)\n",
        "best_lambda = np.zeros(3)\n",
        "all_val_loss = [\n",
        "    np.zeros(len(potential_lambdas)),\n",
        "    np.zeros(len(potential_lambdas)),\n",
        "    np.zeros(len(potential_lambdas)),\n",
        "]\n",
        "\n",
        "# Train all models\n",
        "\n",
        "for i in range(3):\n",
        "    lowest_error = np.inf\n",
        "    for j, lam in enumerate(potential_lambdas):\n",
        "        print(f\"Trying lambda {lam} on dataset {i + 1}\")\n",
        "\n",
        "        trained_beta = cd_lasso(\n",
        "            all_training[i][1],\n",
        "            all_training[i][0],\n",
        "            lambda_val=lam,\n",
        "            iter=1000,\n",
        "        )\n",
        "        val_loss = np.sum((all_training[i][3] - all_training[i][2] @ trained_beta) ** 2) / (\n",
        "            2 * all_training[i][2].shape[0]\n",
        "        )\n",
        "\n",
        "        all_val_loss[i][j] = val_loss\n",
        "\n",
        "        if val_loss < lowest_error:\n",
        "            lowest_error = val_loss\n",
        "            best_lambda[i] = lam\n",
        "\n",
        "    print(f\"Finished dataset {i + 1}\")\n",
        "\n",
        "best_lambda\n",
        "\n",
        "# 0.35, 0.55, 0.1\n",
        "\n",
        "fit1 = cd_lasso(d1train_y, d1train_x, lambda_val=0.35, iter=1000)\n",
        "fit2 = cd_lasso(d2train_y, d2train_x, lambda_val=0.55, iter=1000)\n",
        "fit3 = cd_lasso(d3train_y, d3train_x, lambda_val=0.1, iter=1000)\n",
        "\n",
        "all_val_loss\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(potential_lambdas, all_val_loss[0], marker='o')\n",
        "plt.title(\"Dataset 1 Validation Loss per Lambda\")\n",
        "plt.xlabel(\"Lambdas\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(potential_lambdas, all_val_loss[1], marker='o')\n",
        "plt.title(\"Dataset 2 Validation Loss per Lambda\")\n",
        "plt.xlabel(\"Lambdas\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(potential_lambdas, all_val_loss[2], marker='o')\n",
        "plt.title(\"Dataset 3 Validation Loss per Lambda\")\n",
        "plt.xlabel(\"Lambdas\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Which coefficients are non-zero\n",
        "\n",
        "np.where(fit1 != 0)[0] + 1\n",
        "np.where(fit2 != 0)[0] + 1\n",
        "np.where(fit3 != 0)[0] + 1\n",
        "\n",
        "# Which coefficients are non-zero across all models\n",
        "\n",
        "np.where((fit1 != 0) & (fit2 != 0) & (fit3 != 0))[0] + 1\n",
        "\n",
        "# Test errors\n",
        "\n",
        "np.sum((test_y - test_x @ fit1) ** 2) / (2 * test_x.shape[0])\n",
        "np.sum((test_y - test_x @ fit2) ** 2) / (2 * test_x.shape[0])\n",
        "np.sum((test_y - test_x @ fit3) ** 2) / (2 * test_x.shape[0])\n",
        "\n",
        "\n",
        "# PART B\n",
        "\n",
        "l1 = 40\n",
        "l2 = 40\n",
        "l3 = 100\n",
        "beta_common = np.zeros(600)\n",
        "beta_common_old = beta_common.copy()\n",
        "iterations = 5\n",
        "\n",
        "while np.sqrt(np.sum((beta_common - beta_common_old) ** 2)) < 1e-6:\n",
        "    beta1 = cd_lasso(d1train_y, d1train_x, beta=beta_common, iter=iterations, lambda_val=l1)\n",
        "    beta2 = cd_lasso(d2train_y, d2train_x, beta=beta_common, iter=iterations, lambda_val=l2)\n",
        "    beta3 = cd_lasso(d3train_y, d3train_x, beta=beta_common, iter=iterations, lambda_val=l3)\n",
        "\n",
        "    beta_common_old = beta_common\n",
        "    beta_common = (200 / 1000) * beta1 + (300 / 1000) * beta2 + (500 / 1000) * beta3\n",
        "\n",
        "# Independent validation errors, used to tune l1, l2, l3 by brute-force\n",
        "\n",
        "np.sum((d1val_y - d1val_x @ beta_common) ** 2) / (2 * d1val_x.shape[0])\n",
        "np.sum((d2val_y - d2val_x @ beta_common) ** 2) / (2 * d2val_x.shape[0])\n",
        "np.sum((d3val_y - d3val_x @ beta_common) ** 2) / (2 * d3val_x.shape[0])\n",
        "\n",
        "# Which coefficients are non-zero\n",
        "\n",
        "np.where(beta_common != 0)[0] + 1\n",
        "\n",
        "# Confusion Matrix computations\n",
        "\n",
        "truth = np.where(beta_common == 0, 0, 1)\n",
        "pred1 = np.where(fit1 == 0, 0, 1)\n",
        "pred2 = np.where(fit2 == 0, 0, 1)\n",
        "pred3 = np.where(fit3 == 0, 0, 1)\n",
        "\n",
        "# Dataset 1 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred1 == 1)), np.sum((truth == 0) & (pred1 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred1 == 0)), np.sum((truth == 0) & (pred1 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Dataset 2 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred2 == 1)), np.sum((truth == 0) & (pred2 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred2 == 0)), np.sum((truth == 0) & (pred2 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Dataset 3 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred3 == 1)), np.sum((truth == 0) & (pred3 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred3 == 0)), np.sum((truth == 0) & (pred3 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Test error\n",
        "\n",
        "np.sum((test_y - test_x @ beta_common) ** 2) / (2 * test_x.shape[0])\n",
        "\n",
        "# Re-Run for 10 iterations\n",
        "\n",
        "l1 = 40\n",
        "l2 = 40\n",
        "l3 = 100\n",
        "beta_common = np.zeros(600)\n",
        "beta_common_old = beta_common.copy()\n",
        "iterations = 10\n",
        "\n",
        "while np.sqrt(np.sum((beta_common - beta_common_old) ** 2)) < 1e-6:\n",
        "    beta1 = cd_lasso(d1train_y, d1train_x, beta=beta_common, iter=iterations, lambda_val=l1)\n",
        "    beta2 = cd_lasso(d2train_y, d2train_x, beta=beta_common, iter=iterations, lambda_val=l2)\n",
        "    beta3 = cd_lasso(d3train_y, d3train_x, beta=beta_common, iter=iterations, lambda_val=l3)\n",
        "\n",
        "    beta_common_old = beta_common\n",
        "    beta_common = (200 / 1000) * beta1 + (300 / 1000) * beta2 + (500 / 1000) * beta3\n",
        "\n",
        "# Independent validation errors, used to tune l1, l2, l3 by brute-force\n",
        "\n",
        "np.sum((d1val_y - d1val_x @ beta_common) ** 2) / (2 * d1val_x.shape[0])\n",
        "np.sum((d2val_y - d2val_x @ beta_common) ** 2) / (2 * d2val_x.shape[0])\n",
        "np.sum((d3val_y - d3val_x @ beta_common) ** 2) / (2 * d3val_x.shape[0])\n",
        "\n",
        "# Which coefficients are non-zero\n",
        "\n",
        "np.where(beta_common != 0)[0] + 1\n",
        "\n",
        "# Confusion Matrix computations\n",
        "\n",
        "truth = np.where(beta_common == 0, 0, 1)\n",
        "pred1 = np.where(fit1 == 0, 0, 1)\n",
        "pred2 = np.where(fit2 == 0, 0, 1)\n",
        "pred3 = np.where(fit3 == 0, 0, 1)\n",
        "\n",
        "# Dataset 1 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred1 == 1)), np.sum((truth == 0) & (pred1 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred1 == 0)), np.sum((truth == 0) & (pred1 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Dataset 2 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred2 == 1)), np.sum((truth == 0) & (pred2 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred2 == 0)), np.sum((truth == 0) & (pred2 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Dataset 3 Confusion Matrix\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"Truth/Predicted\": [\"True 1\", \"True 0\"],\n",
        "        \"Predicted 1\": [np.sum((truth == 1) & (pred3 == 1)), np.sum((truth == 0) & (pred3 == 1))],\n",
        "        \"Predicted 0\": [np.sum((truth == 1) & (pred3 == 0)), np.sum((truth == 0) & (pred3 == 0))],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Test error\n",
        "\n",
        "np.sum((test_y - test_x @ beta_common) ** 2) / (2 * test_x.shape[0])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}